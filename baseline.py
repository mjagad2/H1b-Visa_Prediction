# -*- coding: utf-8 -*-
"""baseline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ELj28VKxQe8E1h-VnIbU6HMb9ezVIUaB
""" 
import numpy as np 
import sklearn
from statistics import mean 
from sklearn import metrics
from sklearn import model_selection
from sklearn.preprocessing import OneHotEncoder #ONE HOT ENCODING
from sklearn.ensemble import RandomForestClassifier #Build model - Random Forest Classifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score

class BaselineClasifier():
    """
    Baseline classifier that predicts the class base on the mode of the labels.
    """
    def __init__(self, np):
        self.central_tendency = None
        self.np = np
        
    def fit(self, data, y, central_t='mode'):
        # Count labels and find the most frequent one 
        label, counts = self.np.unique(y, return_counts=True) 
        if central_t == 'mode':
            self.central_tendency = label[counts.argmax()]
            
        elif central_t == 'mean':
            self.central_tendency = round(self.np.sum(y)/len(y))
        # Return an array with size equal to the data size  and each element setted to the mode.
        return self
    
    def predict(self, data):
        result = self.np.full(data.shape[0], self.central_tendency)
        return result

def run_clasifier(X_train, y_train, X_test, numpy, class_type='mode'):
    baseline_clasifier = BaselineClasifier(numpy)
    classifier = baseline_clasifier.fit(X_train, y_train, class_type)
    return baseline_clasifier.predict(X_test)

def compute_accuracy(validation, prediction):
    comp = prediction == validation 
    match_counts = np.count_nonzero(comp == True) 
    clasifier_accuracy = match_counts/len(validation)
    return clasifier_accuracy  

def compute_AUC(y, prediction):
    auc = None
    try:
        auc = roc_auc_score(y, prediction)
    except ValueError:
        pass
    return auc

def Acceptance_baseline(X,y):
    """
    Baseline classifier function used for prdicting acceptance/rejection
    """
    accuracies = []
    AUCs = []
    kf = sklearn.model_selection.KFold(n_splits=4, random_state=1, shuffle=True)# Testing with K-folds 
    for train_idx, test_idx in kf.split(X):
        X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx] 
        prediction = run_clasifier(X_train, y_train, X_test, np)
        fold_accuracy = compute_accuracy(y_test, prediction)
        fold_AUC = compute_AUC(y_test, prediction)
        accuracies.append(fold_accuracy)
        if fold_AUC != None: AUCs.append(fold_AUC)
    baseline_clasifier_accuracy = mean(accuracies)
    print('Baseline accuracy (K-fold): ', baseline_clasifier_accuracy)
    print('AUC K-fold: ', mean(AUCs))
    return baseline_clasifier_accuracy,mean(AUCs)

def baseline_wage(X,y):
    """
    Baseline classifier function used for predicting wage rate 
    """
    accuracies = []
    AUCs = []
    kf = sklearn.model_selection.KFold(n_splits=4, random_state=1, shuffle=True)# Testing with K-folds 
    for train_idx, test_idx in kf.split(X):
        X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx] 
        prediction = run_clasifier(X_train, y_train, X_test, np)
        fold_accuracy = compute_accuracy(y_test, prediction)
        fold_AUC = compute_AUC(y_test, prediction)
        accuracies.append(fold_accuracy)
        if fold_AUC != None: AUCs.append(fold_AUC)
    baseline_clasifier_accuracy = mean(accuracies)
    return baseline_clasifier_accuracy

def baseline_wage_kfold(X,y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)# Testing with regular split
    prediction = run_clasifier(X_train, y_train, X_test, np)
    split_accuracy = compute_accuracy(y_test, prediction)
    return split_accuracy
